{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mW1lklPIwkq",
        "outputId": "94ce87f0-44d3-43e5-dc6e-81c93a5924ca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/DeepQLearn_FlappyBird"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4RZ2JnIJ0bc",
        "outputId": "b9b6fad9-ac6d-4b2e-c0cb-f65f60500e4c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/DeepQLearn_FlappyBird\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install virtual environment package\n",
        "!pip install virtualenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdTeIDosIdod",
        "outputId": "19b28cb6-8d77-4f08-ac3b-a51bad312550"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: virtualenv in /usr/local/lib/python3.10/dist-packages (20.25.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (0.3.8)\n",
            "Requirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (3.13.1)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (4.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTrl-Gr3IFBb",
        "outputId": "c8c5f1ae-a431-40d2-9761-7c3c55e93b7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created virtual environment CPython3.10.12.final.0-64 in 10218ms\n",
            "  creator CPython3Posix(dest=/content/drive/MyDrive/DeepQLearn_FlappyBird/myenv, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
            "    added seed packages: pip==23.3.1, setuptools==69.0.2, wheel==0.42.0\n",
            "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n"
          ]
        }
      ],
      "source": [
        "# Create a new virtual environment\n",
        "!virtualenv myenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Activate the virtual environment\n",
        "!source myenv/bin/activate"
      ],
      "metadata": {
        "id": "zo3_SYOnI-BX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install packages within the virtual environment\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4C70zwNmJaAD",
        "outputId": "1b2be21a-018b-4194-ab8a-fa6b98f4b43d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.5.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (4.8.0.76)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.23.5)\n",
            "Collecting tensorboardX (from -r requirements.txt (line 6))\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (2.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX->-r requirements.txt (line 6)) (23.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX->-r requirements.txt (line 6)) (3.20.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 4)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 4)) (1.3.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NMvj_liEK5UM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsI8LzYWK7U1",
        "outputId": "d5913e72-1ec8-4cc3-afed-1257c4d571fa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pygame 2.5.2 (SDL 2.28.2, Python 3.10.12)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
            "error: XDG_RUNTIME_DIR not set in the environment.\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "Iteration: 2/100000, Action: 0, Loss: 0.009979200549423695, Epsilon 0.1, Reward: 0.1, Q-value: 0.0004902554792352021\n",
            "Iteration: 3/100000, Action: 0, Loss: 0.009983256459236145, Epsilon 0.099999001, Reward: 0.1, Q-value: 0.0003772474592551589\n",
            "Iteration: 4/100000, Action: 0, Loss: 0.009998013265430927, Epsilon 0.099998002, Reward: 0.1, Q-value: 0.0003292043402325362\n",
            "Iteration: 5/100000, Action: 0, Loss: 0.010006828233599663, Epsilon 0.099997003, Reward: 0.1, Q-value: 0.0004840283654630184\n",
            "Iteration: 6/100000, Action: 0, Loss: 0.010013428516685963, Epsilon 0.09999600400000001, Reward: 0.1, Q-value: 0.0006700654630549252\n",
            "Iteration: 7/100000, Action: 0, Loss: 0.009998681955039501, Epsilon 0.099995005, Reward: 0.1, Q-value: 0.000891632866114378\n",
            "Iteration: 8/100000, Action: 0, Loss: 0.009999162517488003, Epsilon 0.09999400600000001, Reward: 0.1, Q-value: 0.0005337154725566506\n",
            "Iteration: 9/100000, Action: 1, Loss: 0.010012954473495483, Epsilon 0.099993007, Reward: 0.1, Q-value: 0.0005685085779987276\n",
            "Iteration: 10/100000, Action: 0, Loss: 0.010004482232034206, Epsilon 0.09999200800000001, Reward: 0.1, Q-value: 0.0011404602555558085\n",
            "Iteration: 11/100000, Action: 0, Loss: 0.010003605857491493, Epsilon 0.09999100899999999, Reward: 0.1, Q-value: 0.0008471557521261275\n",
            "Iteration: 12/100000, Action: 0, Loss: 0.00999943632632494, Epsilon 0.09999001, Reward: 0.1, Q-value: 0.0008498000097461045\n",
            "Iteration: 13/100000, Action: 0, Loss: 0.010003096424043179, Epsilon 0.09998901100000002, Reward: 0.1, Q-value: 0.000663353712297976\n",
            "Perform a random action\n",
            "Iteration: 14/100000, Action: 0, Loss: 0.010009165853261948, Epsilon 0.099988012, Reward: 0.1, Q-value: 0.0009004541207104921\n",
            "Iteration: 15/100000, Action: 0, Loss: 0.010017002001404762, Epsilon 0.09998701300000001, Reward: 0.1, Q-value: 0.001336913206614554\n",
            "Iteration: 16/100000, Action: 0, Loss: 0.010002080351114273, Epsilon 0.099986014, Reward: 0.1, Q-value: 0.0019591194577515125\n",
            "Iteration: 17/100000, Action: 0, Loss: 0.010003827512264252, Epsilon 0.09998501500000001, Reward: 0.1, Q-value: 0.0009351621847599745\n",
            "Iteration: 18/100000, Action: 0, Loss: 0.010002587921917439, Epsilon 0.09998401600000001, Reward: 0.1, Q-value: 0.0011003488907590508\n",
            "Iteration: 19/100000, Action: 0, Loss: 0.010005754418671131, Epsilon 0.09998301700000001, Reward: 0.1, Q-value: 0.0010339636355638504\n",
            "Iteration: 20/100000, Action: 0, Loss: 0.01000683382153511, Epsilon 0.099982018, Reward: 0.1, Q-value: 0.0013525624526664615\n",
            "Iteration: 21/100000, Action: 0, Loss: 0.01000512670725584, Epsilon 0.099981019, Reward: 0.1, Q-value: 0.0015027105109766126\n",
            "Iteration: 22/100000, Action: 0, Loss: 0.010007617063820362, Epsilon 0.09998002, Reward: 0.1, Q-value: 0.0013838884187862277\n",
            "Iteration: 23/100000, Action: 0, Loss: 0.010002877563238144, Epsilon 0.09997902100000002, Reward: 0.1, Q-value: 0.0016945739043876529\n",
            "Perform a random action\n",
            "Iteration: 24/100000, Action: 0, Loss: 0.010007347911596298, Epsilon 0.099978022, Reward: 0.1, Q-value: 0.001222389517351985\n",
            "Iteration: 25/100000, Action: 0, Loss: 0.01000223308801651, Epsilon 0.09997702300000001, Reward: 0.1, Q-value: 0.001770024304278195\n",
            "Iteration: 26/100000, Action: 0, Loss: 0.010000067763030529, Epsilon 0.099976024, Reward: 0.1, Q-value: 0.0012160284677520394\n",
            "Iteration: 27/100000, Action: 0, Loss: 0.009998077526688576, Epsilon 0.09997502500000001, Reward: 0.1, Q-value: 0.000966182560659945\n",
            "Iteration: 28/100000, Action: 0, Loss: 0.009999977424740791, Epsilon 0.099974026, Reward: 0.1, Q-value: 0.0007125635747797787\n",
            "Iteration: 29/100000, Action: 0, Loss: 0.00999599602073431, Epsilon 0.099973027, Reward: 0.1, Q-value: 0.000967786181718111\n",
            "Iteration: 30/100000, Action: 1, Loss: 0.009996387176215649, Epsilon 0.09997202800000002, Reward: 0.1, Q-value: 0.00045355322072282434\n",
            "Iteration: 31/100000, Action: 0, Loss: 0.009997298009693623, Epsilon 0.099971029, Reward: 0.1, Q-value: 0.00046022547758184373\n",
            "Iteration: 32/100000, Action: 0, Loss: 0.009996285662055016, Epsilon 0.09997003000000002, Reward: 0.1, Q-value: 0.000582878477871418\n",
            "Iteration: 33/100000, Action: 0, Loss: 0.009995067492127419, Epsilon 0.099969031, Reward: 0.1, Q-value: 0.0004281706642359495\n",
            "Iteration: 34/100000, Action: 0, Loss: 0.009997803717851639, Epsilon 0.09996803200000001, Reward: 0.1, Q-value: 0.0001617899542907253\n",
            "Iteration: 35/100000, Action: 0, Loss: 0.010000715032219887, Epsilon 0.09996703300000001, Reward: 0.1, Q-value: -0.00048577628331258893\n",
            "Iteration: 36/100000, Action: 0, Loss: 0.009996984153985977, Epsilon 0.09996603400000001, Reward: 0.1, Q-value: 0.0007749664946459234\n",
            "Iteration: 37/100000, Action: 1, Loss: 0.009989568032324314, Epsilon 0.09996503500000001, Reward: 0.1, Q-value: 0.0008215244160965085\n",
            "Perform a random action\n",
            "Iteration: 38/100000, Action: 0, Loss: 0.010011433623731136, Epsilon 0.099964036, Reward: 0.1, Q-value: 0.0009688080754131079\n",
            "Iteration: 39/100000, Action: 1, Loss: 0.009995512664318085, Epsilon 0.099963037, Reward: 0.1, Q-value: 0.001981676323339343\n",
            "Iteration: 40/100000, Action: 1, Loss: 0.010003249160945415, Epsilon 0.09996203800000002, Reward: 0.1, Q-value: 0.001825383398681879\n",
            "Iteration: 41/100000, Action: 1, Loss: 0.010010801255702972, Epsilon 0.099961039, Reward: 0.1, Q-value: 0.0017892762552946806\n",
            "Iteration: 42/100000, Action: 1, Loss: 0.009991912171244621, Epsilon 0.09996004000000001, Reward: 0.1, Q-value: 0.002018268685787916\n",
            "Iteration: 43/100000, Action: 1, Loss: 0.010012809187173843, Epsilon 0.099959041, Reward: 0.1, Q-value: 0.001700623077340424\n",
            "Iteration: 44/100000, Action: 1, Loss: 0.010005276650190353, Epsilon 0.09995804200000001, Reward: 0.1, Q-value: 0.002287699840962887\n",
            "Iteration: 45/100000, Action: 1, Loss: 0.010000292211771011, Epsilon 0.099957043, Reward: 0.1, Q-value: 0.0018280120566487312\n",
            "Iteration: 46/100000, Action: 1, Loss: 0.010007590986788273, Epsilon 0.09995604400000001, Reward: 0.1, Q-value: 0.0020256261341273785\n",
            "Iteration: 47/100000, Action: 1, Loss: 0.009994016960263252, Epsilon 0.099955045, Reward: 0.1, Q-value: 0.0022656985092908144\n",
            "Iteration: 48/100000, Action: 1, Loss: 0.009996792301535606, Epsilon 0.099954046, Reward: 0.1, Q-value: 0.0019450258696451783\n",
            "Iteration: 49/100000, Action: 1, Loss: 0.010008446872234344, Epsilon 0.099953047, Reward: 0.1, Q-value: 0.002085822867229581\n",
            "Iteration: 50/100000, Action: 0, Loss: 0.04103011265397072, Epsilon 0.099952048, Reward: -1, Q-value: 0.0015929563669487834\n",
            "Iteration: 51/100000, Action: 1, Loss: 0.04102683812379837, Epsilon 0.099951049, Reward: 0.1, Q-value: 0.002019951120018959\n",
            "Iteration: 52/100000, Action: 0, Loss: 0.0410008504986763, Epsilon 0.09995005000000001, Reward: 0.1, Q-value: 0.0011673549888655543\n",
            "Iteration: 53/100000, Action: 0, Loss: 0.04100658372044563, Epsilon 0.099949051, Reward: 0.1, Q-value: 0.0007464031805284321\n",
            "Perform a random action\n",
            "Iteration: 54/100000, Action: 1, Loss: 0.009999729692935944, Epsilon 0.09994805200000001, Reward: 0.1, Q-value: 0.0007585628773085773\n",
            "Perform a random action\n",
            "Iteration: 55/100000, Action: 0, Loss: 0.040990255773067474, Epsilon 0.099947053, Reward: 0.1, Q-value: 0.0008433212642557919\n",
            "Iteration: 56/100000, Action: 0, Loss: 0.04096474498510361, Epsilon 0.099946054, Reward: 0.1, Q-value: 0.0004859695618506521\n",
            "Iteration: 57/100000, Action: 0, Loss: 0.040956806391477585, Epsilon 0.09994505500000002, Reward: 0.1, Q-value: 0.0007893634028732777\n",
            "Iteration: 58/100000, Action: 0, Loss: 0.04094768315553665, Epsilon 0.099944056, Reward: 0.1, Q-value: 0.0008097558165900409\n",
            "Iteration: 59/100000, Action: 0, Loss: 0.040923215448856354, Epsilon 0.09994305700000002, Reward: 0.1, Q-value: 0.00095863122260198\n",
            "Iteration: 60/100000, Action: 0, Loss: 0.009983016178011894, Epsilon 0.099942058, Reward: 0.1, Q-value: 0.0010016750311478972\n",
            "Iteration: 61/100000, Action: 0, Loss: 0.009986719116568565, Epsilon 0.09994105900000001, Reward: 0.1, Q-value: 0.0011665860656648874\n",
            "Iteration: 62/100000, Action: 0, Loss: 0.01001832727342844, Epsilon 0.09994006, Reward: 0.1, Q-value: 0.0009337285882793367\n",
            "Iteration: 63/100000, Action: 0, Loss: 0.010001856833696365, Epsilon 0.09993906100000001, Reward: 0.1, Q-value: 9.774859790923074e-05\n",
            "Iteration: 64/100000, Action: 0, Loss: 0.0408644825220108, Epsilon 0.09993806200000001, Reward: 0.1, Q-value: 0.00011118930706288666\n",
            "Iteration: 65/100000, Action: 0, Loss: 0.009995752945542336, Epsilon 0.099937063, Reward: 0.1, Q-value: 3.6539458960760385e-05\n",
            "Iteration: 66/100000, Action: 0, Loss: 0.010004399344325066, Epsilon 0.099936064, Reward: 0.1, Q-value: 0.00020711410616058856\n",
            "Iteration: 67/100000, Action: 1, Loss: 0.010012582875788212, Epsilon 0.099935065, Reward: 0.1, Q-value: -0.0002716008457355201\n",
            "Iteration: 68/100000, Action: 1, Loss: 0.010002244263887405, Epsilon 0.099934066, Reward: 0.1, Q-value: -0.00013577868230640888\n",
            "Perform a random action\n",
            "Iteration: 69/100000, Action: 0, Loss: 0.04084201529622078, Epsilon 0.09993306700000001, Reward: 0.1, Q-value: -5.8009660278912634e-05\n",
            "Iteration: 70/100000, Action: 1, Loss: 0.01000024564564228, Epsilon 0.099932068, Reward: 0.1, Q-value: 0.00010700593702495098\n",
            "Iteration: 71/100000, Action: 1, Loss: 0.040827009826898575, Epsilon 0.09993106900000001, Reward: 0.1, Q-value: 0.00038797419983893633\n",
            "Iteration: 72/100000, Action: 1, Loss: 0.009996484033763409, Epsilon 0.09993007, Reward: 0.1, Q-value: 0.0006734844064339995\n",
            "Iteration: 73/100000, Action: 1, Loss: 0.04082021117210388, Epsilon 0.09992907100000001, Reward: 0.1, Q-value: 0.0008479400421492755\n",
            "Iteration: 74/100000, Action: 1, Loss: 0.04082253575325012, Epsilon 0.09992807200000002, Reward: 0.1, Q-value: 0.00030944120953790843\n",
            "Iteration: 75/100000, Action: 1, Loss: 0.04080168530344963, Epsilon 0.099927073, Reward: 0.1, Q-value: 0.0005653182743117213\n",
            "Iteration: 76/100000, Action: 1, Loss: 0.010008305311203003, Epsilon 0.09992607400000002, Reward: 0.1, Q-value: 0.0006313926423899829\n",
            "Iteration: 77/100000, Action: 1, Loss: 0.010004140436649323, Epsilon 0.099925075, Reward: 0.1, Q-value: 0.00013629425666294992\n",
            "Iteration: 78/100000, Action: 1, Loss: 0.01002591010183096, Epsilon 0.099924076, Reward: 0.1, Q-value: -0.0005321921780705452\n",
            "Iteration: 79/100000, Action: 1, Loss: 0.010012758895754814, Epsilon 0.099923077, Reward: 0.1, Q-value: -0.000366764870705083\n",
            "Iteration: 80/100000, Action: 1, Loss: 0.009981932118535042, Epsilon 0.099922078, Reward: 0.1, Q-value: -0.000711521424818784\n",
            "Iteration: 81/100000, Action: 1, Loss: 0.010001939721405506, Epsilon 0.09992107900000001, Reward: 0.1, Q-value: -0.0011848959838971496\n",
            "Iteration: 82/100000, Action: 1, Loss: 0.010010912083089352, Epsilon 0.09992008, Reward: 0.1, Q-value: -0.0015375749208033085\n",
            "Iteration: 83/100000, Action: 1, Loss: 0.040712226182222366, Epsilon 0.099919081, Reward: 0.1, Q-value: -0.0014096107333898544\n",
            "Iteration: 84/100000, Action: 1, Loss: 0.00998888909816742, Epsilon 0.09991808199999999, Reward: 0.1, Q-value: -0.0014768955297768116\n",
            "Iteration: 85/100000, Action: 1, Loss: 0.009971982799470425, Epsilon 0.099917083, Reward: 0.1, Q-value: -0.0015577477170154452\n",
            "Iteration: 86/100000, Action: 0, Loss: 0.010002316907048225, Epsilon 0.09991608400000002, Reward: 0.1, Q-value: -0.0004712626105174422\n",
            "Iteration: 87/100000, Action: 0, Loss: 0.010006977245211601, Epsilon 0.099915085, Reward: 0.1, Q-value: -0.0007904820377007127\n",
            "Iteration: 88/100000, Action: 0, Loss: 0.00998624972999096, Epsilon 0.09991408600000001, Reward: 0.1, Q-value: -0.0010365333873778582\n",
            "Iteration: 89/100000, Action: 1, Loss: 0.040722716599702835, Epsilon 0.099913087, Reward: 0.1, Q-value: -0.0003963389608543366\n",
            "Iteration: 90/100000, Action: 1, Loss: 0.009986210614442825, Epsilon 0.09991208800000001, Reward: 0.1, Q-value: -0.0003519893216434866\n",
            "Iteration: 91/100000, Action: 0, Loss: 0.009991825558245182, Epsilon 0.09991108900000001, Reward: 0.1, Q-value: -0.0005027001607231796\n",
            "Iteration: 92/100000, Action: 1, Loss: 0.009991567581892014, Epsilon 0.09991009000000001, Reward: 0.1, Q-value: -0.0006238119676709175\n",
            "Iteration: 93/100000, Action: 1, Loss: 0.00999400857836008, Epsilon 0.099909091, Reward: 0.1, Q-value: -4.167548468103632e-06\n",
            "Iteration: 94/100000, Action: 1, Loss: 0.009983648546040058, Epsilon 0.099908092, Reward: 0.1, Q-value: 0.000604844419285655\n",
            "Iteration: 95/100000, Action: 1, Loss: 0.0406750924885273, Epsilon 0.099907093, Reward: 0.1, Q-value: 0.0004368394729681313\n",
            "Iteration: 96/100000, Action: 1, Loss: 0.009984936565160751, Epsilon 0.099906094, Reward: 0.1, Q-value: 0.00019695375522132963\n",
            "Iteration: 97/100000, Action: 1, Loss: 0.04066038876771927, Epsilon 0.099905095, Reward: 0.1, Q-value: 0.0006826583412475884\n",
            "Iteration: 98/100000, Action: 1, Loss: 0.0406615175306797, Epsilon 0.09990409600000001, Reward: 0.1, Q-value: 0.0002771395957097411\n",
            "Iteration: 99/100000, Action: 1, Loss: 0.010002026334404945, Epsilon 0.099903097, Reward: 0.1, Q-value: 0.0006677327328361571\n",
            "Iteration: 100/100000, Action: 1, Loss: 0.010027436539530754, Epsilon 0.09990209800000001, Reward: -1, Q-value: 0.00019229693862143904\n",
            "Iteration: 101/100000, Action: 1, Loss: 0.01000484824180603, Epsilon 0.099901099, Reward: 0.1, Q-value: 0.0007355058914981782\n",
            "Iteration: 102/100000, Action: 0, Loss: 0.04064970836043358, Epsilon 0.0999001, Reward: 0.1, Q-value: 0.00018921037553809583\n",
            "Iteration: 103/100000, Action: 1, Loss: 0.07159262895584106, Epsilon 0.09989910100000002, Reward: 0.1, Q-value: -6.118162855273113e-05\n",
            "Iteration: 104/100000, Action: 0, Loss: 0.009986989200115204, Epsilon 0.099898102, Reward: 0.1, Q-value: 0.0005216639838181436\n",
            "Iteration: 105/100000, Action: 0, Loss: 0.07153421640396118, Epsilon 0.09989710300000001, Reward: 0.1, Q-value: 0.0007985305273905396\n",
            "Iteration: 106/100000, Action: 0, Loss: 0.009995190426707268, Epsilon 0.099896104, Reward: 0.1, Q-value: 0.0005319821066223085\n",
            "Iteration: 107/100000, Action: 0, Loss: 0.04091022536158562, Epsilon 0.09989510500000001, Reward: 0.1, Q-value: 0.0006543100462295115\n",
            "Iteration: 108/100000, Action: 0, Loss: 0.04061035439372063, Epsilon 0.09989410600000001, Reward: 0.1, Q-value: 0.000403282989282161\n",
            "Iteration: 109/100000, Action: 0, Loss: 0.010003064759075642, Epsilon 0.09989310700000001, Reward: 0.1, Q-value: 0.0005871023167856038\n",
            "Iteration: 110/100000, Action: 0, Loss: 0.009989704936742783, Epsilon 0.09989210800000001, Reward: 0.1, Q-value: 0.0008204475161619484\n",
            "Iteration: 111/100000, Action: 0, Loss: 0.00999380648136139, Epsilon 0.099891109, Reward: 0.1, Q-value: 0.0004658896359615028\n",
            "Iteration: 112/100000, Action: 0, Loss: 0.009997976943850517, Epsilon 0.09989011, Reward: 0.1, Q-value: 0.0006568006938323379\n",
            "Iteration: 113/100000, Action: 0, Loss: 0.010003611445426941, Epsilon 0.09988911100000002, Reward: 0.1, Q-value: 8.453176997136325e-05\n",
            "Iteration: 114/100000, Action: 0, Loss: 0.010017593391239643, Epsilon 0.099888112, Reward: 0.1, Q-value: -0.0002581311564426869\n",
            "Iteration: 115/100000, Action: 0, Loss: 0.07143465429544449, Epsilon 0.09988711300000001, Reward: 0.1, Q-value: -0.00013113266322761774\n",
            "Iteration: 116/100000, Action: 0, Loss: 0.009976102970540524, Epsilon 0.099886114, Reward: 0.1, Q-value: 0.00016855723515618593\n",
            "Iteration: 117/100000, Action: 0, Loss: 0.040832437574863434, Epsilon 0.09988511500000001, Reward: 0.1, Q-value: 8.037022780627012e-05\n",
            "Iteration: 118/100000, Action: 0, Loss: 0.010003369301557541, Epsilon 0.099884116, Reward: 0.1, Q-value: 4.038533006678335e-06\n",
            "Iteration: 119/100000, Action: 1, Loss: 0.009986607357859612, Epsilon 0.09988311700000001, Reward: 0.1, Q-value: -0.00037462785257957876\n",
            "Iteration: 120/100000, Action: 0, Loss: 0.009987028315663338, Epsilon 0.099882118, Reward: 0.1, Q-value: -0.00030012725619599223\n",
            "Iteration: 121/100000, Action: 0, Loss: 0.009985572658479214, Epsilon 0.099881119, Reward: 0.1, Q-value: -0.00037111854180693626\n",
            "Iteration: 122/100000, Action: 1, Loss: 0.07132718712091446, Epsilon 0.09988012, Reward: 0.1, Q-value: -0.0004161192919127643\n",
            "Iteration: 123/100000, Action: 1, Loss: 0.040527015924453735, Epsilon 0.099879121, Reward: 0.1, Q-value: -0.00043404317693784833\n",
            "Perform a random action\n",
            "Iteration: 124/100000, Action: 0, Loss: 0.04052512347698212, Epsilon 0.099878122, Reward: 0.1, Q-value: -0.0007970324950292706\n",
            "Iteration: 125/100000, Action: 1, Loss: 0.04078204184770584, Epsilon 0.09987712300000001, Reward: 0.1, Q-value: 4.063433880219236e-05\n",
            "\n"
          ]
        }
      ]
    }
  ]
}